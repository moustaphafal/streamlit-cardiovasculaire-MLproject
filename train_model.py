"""
Script d'entra√Ænement du mod√®le de pr√©diction cardiovasculaire

Ce script est bas√© sur le notebook "Projet ML - Cardiovasculaire.ipynb"
Il utilise le dataset heart.csv et entra√Æne un mod√®le de R√©gression Logistique.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
import pickle
from pathlib import Path

def preprocess_data(df):
    """
    Pr√©traite les donn√©es comme dans le notebook
    - Remplace les valeurs aberrantes par NaN
    - Remplit les valeurs manquantes avec la m√©diane
    """
    print("üîß Pr√©traitement des donn√©es...")
    
    # Isoler les valeurs aberrantes
    df['RestingBP'] = df['RestingBP'].replace(0, np.nan)
    df['Cholesterol'] = df['Cholesterol'].replace(0, np.nan)
    df.loc[df['Oldpeak'] < 0, 'Oldpeak'] = np.nan
    
    # Remplacer par la m√©diane
    df['RestingBP'].fillna(df['RestingBP'].median(), inplace=True)
    df['Cholesterol'].fillna(df['Cholesterol'].median(), inplace=True)
    df['Oldpeak'].fillna(df['Oldpeak'].median(), inplace=True)
    
    print(f"  ‚úÖ Valeurs aberrantes trait√©es")
    
    return df

def train_model(data_path='data/heart.csv'):
    """
    Entra√Æne le mod√®le de pr√©diction cardiovasculaire
    Suit exactement le processus du notebook
    """
    print("\n" + "="*50)
    print("ü´Ä ENTRA√éNEMENT DU MOD√àLE CARDIOVASCULAIRE")
    print("="*50 + "\n")
    
    # 1. Chargement des donn√©es
    print("üìä Chargement des donn√©es...")
    try:
        df = pd.read_csv(data_path)
        print(f"  ‚úÖ Donn√©es charg√©es: {df.shape[0]} lignes, {df.shape[1]} colonnes")
    except FileNotFoundError:
        print(f"  ‚ùå Fichier {data_path} non trouv√©.")
        return None, None
    
    # 2. Pr√©traitement
    df = preprocess_data(df)
    
    # 3. Encodage des variables cat√©gorielles
    print("\nüîÑ Encodage des variables cat√©gorielles...")
    df_encoded = pd.get_dummies(df, columns=['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], drop_first=True)
    print(f"  ‚úÖ Encodage termin√©: {df_encoded.shape[1]} colonnes")
    
    # 4. S√©paration Features / Target
    print("\nüéØ S√©paration des donn√©es...")
    X = df_encoded.drop('HeartDisease', axis=1)
    y = df_encoded['HeartDisease']
    
    # 5. Standardisation
    print("\nüìè Standardisation des donn√©es num√©riques...")
    col_standardise = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']
    scaler = StandardScaler()
    X[col_standardise] = scaler.fit_transform(X[col_standardise])
    print(f"  ‚úÖ Standardisation appliqu√©e sur {len(col_standardise)} colonnes")
    
    # 6. Split Train/Test
    print("\n‚úÇÔ∏è Division des donn√©es...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=0.2, 
        random_state=42, 
        stratify=y
    )
    print(f"  ‚úÖ Train: {X_train.shape[0]} √©chantillons")
    print(f"  ‚úÖ Test:  {X_test.shape[0]} √©chantillons")
    
    # 7. Entra√Ænement du mod√®le
    print("\nüéì Entra√Ænement du mod√®le R√©gression Logistique...")
    model = LogisticRegression(max_iter=1000, random_state=42)
    model.fit(X_train, y_train)
    print("  ‚úÖ Entra√Ænement termin√©")
    
    # 8. √âvaluation
    print("\nüìà √âvaluation du mod√®le...")
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_proba)
    
    print("\n" + "="*50)
    print("‚ú® R√âSULTATS DU MOD√àLE")
    print("="*50)
    print(f"  üìä Accuracy:  {accuracy:.3f} ({accuracy*100:.1f}%)")
    print(f"  üéØ Precision: {precision:.3f} ({precision*100:.1f}%)")
    print(f"  üîç Recall:    {recall:.3f} ({recall*100:.1f}%)")
    print(f"  ‚öñÔ∏è  F1-Score:  {f1:.3f} ({f1*100:.1f}%)")
    print(f"  üìà ROC-AUC:   {roc_auc:.3f} ({roc_auc*100:.1f}%)")
    print("="*50 + "\n")
    
    # 9. Sauvegarde du mod√®le et du scaler
    print("üíæ Sauvegarde du mod√®le et du scaler...")
    
    # Cr√©er le dossier models s'il n'existe pas
    Path("models").mkdir(exist_ok=True)
    
    # Sauvegarder le mod√®le
    with open('models/heart_disease_model.pkl', 'wb') as file:
        pickle.dump(model, file)
    print("  ‚úÖ Mod√®le sauvegard√©: models/heart_disease_model.pkl")
    
    # Sauvegarder le scaler
    with open('models/scaler.pkl', 'wb') as file:
        pickle.dump(scaler, file)
    print("  ‚úÖ Scaler sauvegard√©: models/scaler.pkl")
    
    print("\n" + "="*50)
    print("‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS!")
    print("="*50 + "\n")
    print("Vous pouvez maintenant lancer l'application Streamlit:")
    print("  üëâ streamlit run app.py\n")
    
    return model, scaler

if __name__ == "__main__":
    train_model()
